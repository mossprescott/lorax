\section{Abstract Syntax Trees}

An open model of ASTs, where new kinds of nodes can be defined at any time.
\begin{enumerate}
\item Arbitrary content.
\item Arbitrary extension.
\item Support the needs of representing programs.
\item Support typical analysis and transformation.
\end{enumerate}

\todo{motivation, goals}


\subsection{Nodes, Values, and References}
In order to build programs directly out of nodes, we need a common representation for nodes which is flexible enough to represent all possible programs, and which supports the kind of editing operations we will want to provide. Therefore, it should provide a natural way to represent the primitive values which appear in most programming languages, and the common ways of aggregating values into larger structures, such as ordered sequences of nodes and groupings of nodes where each serves a particular function.

A \emph{program} is made up of \emph{nodes}. Every node has a \emph{type}, a unique \emph{label}, and a \emph{value}. A node's type identifies it as one of a class of related nodes, all of which have some common meaning (for example, the type \keyword{plus} might represent addition expressions). Although the set of node types is not restricted, they are typically drawn from a finite set of ``defined'' types, which have been given syntactic and semantic meaning by a previous definition. A node's label is an opaque identifier which gives it a distinct identity, and allows references to nodes to survive transformations of the program. A node's value may be: \emph{empty}, if the node type alone carries all the node's meaning; an atomic value, which is a \emph{boolean}, \emph{integer}, or \emph{string} (a sequence of characters which are treated as an indivisible value)\footnote{An alternative would be to treat single characters as a primitive value, and build strings out of sequences of character-valued nodes. For the current purpose, treating strings as atomic is more efficient and simpler to deal with during editing.}; a \emph{sequence} of child nodes; or an (unordered) \emph{map} of \emph{attribute names} to child nodes. A \emph{reference} is a special type of node which has the type \keyword{ref}, and has as its value the label of another node.

The program is \emph{well-formed} if its nodes satisfy the following constraints:
\begin{enumerate}
\item No two nodes have the same label.
\item No node appears as a child of more than one parent, or under more than one index/name of a sequence/map-valued node (so the nodes form a tree).
\item The value of each reference node is the label of some node in the program.
\item Each sequence node contains $n$ children (indexed by consecutive integers $0$ to $n-1$).
\item Each map node contains zero or more children (attributes), each one having a different name.
\end{enumerate}

\todo{figure: some kind of abstract sketch of some nodes with types and labels a, b, c}

Nodes are immutable values. A new node is constructed by supplying the type, label and value, and once constructed cannot be modified in place. By extension, entire programs are immutable values. The tree structure makes it natural to construct a modified program by building a new tree sharing much of the structure of an existing tree (as in a persistent Red-Black tree [cite okasaki?]).

Note that because nodes do not refer to their parents, any node can be considered as the root node of a sub-tree consisting of its descendant nodes. However, such a tree may not be well-formed, because it may contain references to nodes which are not part of the same sub-tree. Such a reference is analogous to a free variable, and can play a similar role. Indeed, one of the reasons for using explicit references via labels is to allow for that possibility.

No particular constraints are placed on nodes which appear in separate programs, or in fact, on the appearance of the same node within multiple programs. That is, if a system contains two different programs, \todo{}

For the sake of modularity, types and attribute names are associated with namespaces, so that simple names can be used without fear of unintentional collisions. 
%For example, a conditional expression in the kernel language (discussed later) is represented as a node of type \keyword{kernel/if} containing attributes \keyword{kernel/if/test}, etc.


\subsection{Specifications}
A \emph{specification} is a set of constraints on the structure of nodes in a program, which can be expressed as predicates on the nodes. A program is \emph{valid} with respect to a certain specification if the arrangement of nodes, values, and references satisfies the specification's constraints. A specification can be thought of as a boolean-valued function over programs producing the result \emph{valid} or \emph{invalid}, in the same way that a conventional parser is a function over strings which returns either \emph{parses} or \emph {doesn't parse}.

For example, a certain specification might include the constraint ``for all nodes $n$, if the type of $n$ is \keyword{if}, then $n$ has an attribute \keyword{test}, whose type is (an instance of) \keyword{expr}.''

In practice a program may contain more than one violation of a specification, and the user will be interested in the nature of each violation in order to be able to fix them (by correcting either the program or the specification). Therefore a specification will typically be implemented in the form of a \emph{checker}, a function over programs which produces a set of \emph{errors} each consisting of a description of the problem and the location where it occurs.

Depending on the nature of the properties being checked, a specification may be defined only in terms of \emph{local} properties of individual nodes and their direct children, or may refer to \emph{non-local} relationships between nodes more distantly connected. In general, local properties are easier to define, easier to check, and easier to understand, so for the most part they are to be preferred. However, certain important specifications are non-local by nature, e.g. type safety. In section 3.2?\todo{}, we describe a particularly direct and convenient way of specifying the basic structural properties which are sufficient to define a useful programming language.

By providing a modular way of describing and checking properties of programs, specifications give much-needed structure to the open model of ASTs described in the preceding sections. But they do so in a way that does not ultimately restrict the user's ability to modify and extend her program. There is an analogy with the multi-level nature of an IDE: the main interface is a text editor, which can be used to enter arbitrary character sequences, but it is augmented with an ``online'' compiler, which parses the character stream into an AST and analyzes the program's types, etc. The information that is gleaned is then fed back to the text editor in the form of syntax hiliting, error indicators, and other helpful indications of the compiler's understanding. However, because in our system the program is not internally represented in an easily readable form, the presentation of it requires a more comprehensive approach.


\subsection{Reduction}\label{reduction}
The next step in making a useful system is a way to produce (multiple) \emph{target} programs from a given \emph{source} program. The central idea is to have a single source program, consisting of nodes in some "user" programming language, which includes a node type for every important programming construct. In an extensible system, the user is able to add new types of nodes to a running system, but the underlying system must be supplied with some fixed set of node types that it understands. The way to bridge this gap is via \emph{reduction}.

As presented here, reduction is a restricted form of \emph{graph reduction}. It is inspired by the macro expansion process of the LISP family of languages (\todo{cite e.g. Scheme}), and in fact the term ``expansion'' might be more appropriate because a typical reduction replaces a more abstract node with a potentially larger number of lower-level nodes.

A source progam is reduced to a target program by applying a \emph{reduction function} to the root node of the source program. If any reduction is possible, the reduction function returns a new, replacement root node, which typically repackages the children of the original root node under some new kind of parent. As long as some reduction is performed, the reduction function is applied repeatedly to the previous result. Eventually, the root node is fully-reduced (the function fails to return a new reduced node). At that point, each child node is reduced in the same way, and a new root node is constructed with the reduced children.

\todo{pseudocode?}

\todo{figure: schematic of a simple tree being reduced in steps}


\subsubsection{Properties of the reduction algorithm}
Because each reduction step constructs an arbitrary replacement node, it's possible to write virtually any transformation as a reduction. This means, for one thing, that reduction does not in general terminate. This generality, and the potential errors it allows, are typical of meta-programming systems; the full power of the language is available at compile-time, including the ability to introduce bad behavior.

During reduction a series of intermediate programs are produced which are partially reduced, and in general do not conform to the source or target specification. It might be interesting to investigate ways of defining specifications and reductions such that it could be statically shown that a valid source program always reduces to a valid target program.

A related issue is the question of what to do when a reduction function encounters a node which does not have the expected attributes. The function could check and simply refuse to reduce any such node, but as a practical matter it's easier to write reductions that assume the nodes they operate on are properly formed to some minimal extent. This can be facilitated by declaring both the specification (e.g. expected attributes for each node type) and the reduction (given a node with those attributes) at the same time.


\subsubsection{Passing information down}
A local reduction works by examining one node at a time, producing a reduced node which combines the children of the original node in a new way, possibly with some additional nodes inserted as well. This is sufficient for most needs, but in some cases it's necessary to propagate some additional information through the reduction process. A simple extension that meets many needs is to augment the reduction function described above to accept an additional \emph{environment} parameter, an arbitrary value, and to return both a reduced node and a new environment value to be propagated. When recursively visiting child nodes, the new value is used in place of the old one. This allows the reduction function to compute values based on the shape of the tree and use them to control some aspects of the reduction. For example, a reduction could keep track of the depth of the tree (distance from the root node).

\todo{Clearer description? Connection with inherited attributes?}


\subsubsection{Tracking source nodes}
When it's desirable to keep track of what source node gave rise to a given target node, the reduction can record the labels of each pair of source and target node, forming a kind of mapping between the parallel trees. For this to work, the reduction function needs to operate strictly on the single node it's given, and not to reach into any child node. This in turn places some constraints on the way the source program is constructed: each node (along with any environment) must bear sufficient information to identify the correct reduction.

\todo{figure: "links" back to source nodes, or would it make more sense later?}


\subsection{Characteristics}
This way of constructing program source has some implications for the way languages can be defined and the way programs can be worked with.

Node types, attributes, and specifications naturally fit with the concepts of \emph{context-free grammars}, which allows specifications to be defined in ways that are familiar to language designers (i.e. with a grammar). Because grammars so-defined will be used only for checking tree structure and not for parsing, they can be constructed in the natural way, without any need for tricks to work around parsing algorithm shortcomings (e.g. left-factoring).

Programs are \emph{self-describing}. Each node carries an explicit declaration of its meaning, and each primitive value is manifestly of a certain type. This is in contrast to a textual language, where the same sequence of characters might represent a name, data, or a keyword, depending on the context in which they appear. This is a major advantage especially for tools that manipulate programs, because no parser is necessary to extract the structure of the program.

Labels provide robust \emph{source locations}. The label provides each node with an identity that survives when the other parts of the program are changed, or when the program is serialized to non-volatile storage, etc. Labels also provide a way for tools (e.g. compilers and debuggers) to refer to source locations in the absence of line numbers. \todo{diff?}

Reference nodes provide a way of referring to entities in a program which can never be ambiguous, and is independent of such language-specific notions as names and scope. Using labels, as opposed to, say, pointers to the referenced node, keeps the tree simple, makes the relationship explicit, and allows references to be inspected without recourse to low-level techniques. It is assumed that the system provides tools specifically for displaying and editing references, as will be discussed in section \todo{??}.

Nodes may be serialized for storage, distributed processing, etc. Assuming a choice of character set and encoding, all the components of a node can be easily converted to a stream of characters. Node types, labels, and attribute names can be simple strings; boolean, integer, string, and name values are easily handled; map and sequence values pose no great challenge. Because the representation permits only trees, each node can be serialized when it first occurs; there's no need for an encoding of back-references. However, the choice of serialized format is not so important as long as it's simple to implement, because the structure of programs is defined at the level of nodes, so any serialized form that preserves the meaning is sufficient.


\subsection{Comparison with Alternatives}
Besides text, a handful of other representations are commonly used to represent source code and/or intermediate representations within tool such as compilers.

\subsubsection{XML}
XML and other related \emph{markup languages}, are designed to augment textual data with explicit structure for a variety of purposes. The structure of an XML document has much in common with the structure of nodes as defined here, and the \emph{XML Infoset}\cite{infoset} model for documents in particular has a similar flavor. However, there are some important differences:
\begin{enumerate}
\item The child elements of each node in an XML document are always in an ordered sequence, while named attributes can contain only simple character data. In \Meta, a node's children may be ordered or named, whichever makes sense, and there is no separate notion of attribute values vs. child nodes.
\item XML is explicitly a format for character streams, onto which an abstract model can be imposed \textit{post-hoc}. This leads to many awkward and ultimately uninteresting problem, such as when to ignore white-space and when it should be included in the data model.
\item Because XML is meant to be human-readable, text-editors are the dominant mode of interaction with it; although there are GUI tools for editing and viewing certain kinds of XML documents (e.g. SVG\cite{svg}, docx\cite{openoffice}), there are no general-purpose tools for working with XML per se.
\item The XML format does not natively offer any equivalent of references, although any number of schemes for referring to nodes have been implemented in various derived formats.
\end{enumerate}

XML's failure as a concrete syntax for programs has been well-established, and stands as an example of the usability challenges posed by representing source code as structured data\cite{?}.

\subsubsection{S-expressions}
Most Lisp\footnote{When I use the term Lisp, I intend to refer to any of the many variants of Lisp, including Maclisp, Common Lisp, Emacs Lisp, Scheme.} programs are written in \emph{S-expressions}, a simple data structure offering only lists, symbols (i.e. names), and some set of values. Because of this simplicity, a simple encoding of S-expressions using parentheses for grouping and white-space to separate tokens is sufficient to allow them to be ``parsed'' from text with minimal effort. This approach gives considerable generality and flexibility, but s-expressions directly in lieu of a concrete syntax has been a highly divisive choice, essentially separating the population of programmers into two ``camps''---those who are put off by sequences of nested paretheses and those who appreciate the beauty of having the structure of the code plainly visible on the page\cite{?}.

It is a major goal of this thesis to establish that some of the benefits of the Lisp model can be realized in the context a language that can be read by ``the rest of us.''

\subsubsection{ADTs}
Haskell/ML-style ADTs with (parameterized) types. Attribute grammars?
%This construction for nodes has some commonalities with the data constructors of a functional language such as Haskell: Nodes are used to build potentially recursive data structures in the same way you build a tree (or indeed an AST) from values. However nodes in this system are not typed, in the sense that a well-formed program can consist of any aggregation of nodes. This flexibility supports both interactivity and extension, but of course it's necessary to have a way to constrain programs to contain meaningful arrangements of nodes.

\todo{connection with TEX? hasn't been used much for source code, not even in CWEB...}

