\section{Foundations}

\subsection{Goals}
An open model of ASTs, where new kinds of nodes can be defined at any time.
\begin{enumerate}
\item Arbitrary content.
\item Arbitrary extension.
\item Support the needs of representing programs.
\item Support typical analysis and transformation.
\end{enumerate}

\subsection{Nodes, Values, and References}
In order to build programs directly out of nodes, we need a common representation for nodes which is flexible enough to represent all possible programs, and which supports the kind of editing operations we will want to provide. Therefore, it should provide a natural way to represent the primitive values which appear in most programming languages, and the common ways of aggregating values into larger structures, such as ordered sequences of nodes and groupings of nodes where each serves a particular function.

A \emph{program} is made up of \emph{nodes}. Every node has a \emph{type}, a unique \emph{label}, and a \emph{value}. A node's type identifies it as one of a class of related nodes, all of which have some common meaning (for example, the type \keyword{plus} might represent addition expressions). Although the set of node types is not restricted, they are typically drawn from a finite set of ``defined'' types, which have been given syntactic and semantic meaning by a previous definition. A node's label is an opaque identifier which gives it a distinct identity, and allows references to nodes to survive transformations of the program. A node's value may be: \emph{empty}, if the node type alone carries all the node's meaning; an atomic value, which is a \emph{boolean}, \emph{integer}, or \emph{string} (a sequence of characters which are treated as an indivisible value)\footnote{An alternative would be to treat single characters as a primitive value, and build strings out of sequences of character-valued nodes. For the current purpose, treating strings as atomic is more efficient and simpler to deal with during editing.}; a \emph{sequence} of child nodes; or a \emph{map} of \emph{attribute names} to child nodes. A \emph{reference} is a special type of node which has the type \keyword{ref}, and has as its value the label of another node.

The program is \emph{well-formed} if its nodes satisfy the following constraints:
\begin{enumerate}
\item No two nodes have the same label.
\item No node appears as a child of more than one parent, or under more than one index/name of a sequence/map-valued node (so the nodes form a tree).
\item The value of each reference node is the label of some node in the program.
\item Each sequence node contains $n$ children (indexed by consecutive integers $0$ to $n-1$).
\item Each map node contains zero or more children (attributes), each one having a different name.
\end{enumerate}

\todo{figure: some kind of abstract sketch of some nodes with types and labels a, b, c}

Nodes are immutable values. A new node is constructed by supplying the type, label and value, and once constructed cannot be modified in place. By extension, entire programs are immutable values. The tree structure makes it natural to construct a modified program by building a new tree sharing much of the structure of an existing tree (as in a persistent Red-Black tree [cite okasaki?]).

Note that because nodes do not refer to their parents, any node can be considered as the root node of a sub-tree consisting of its descendant nodes. However, such a tree may not be well-formed, because it may contain references to nodes which are not part of the same sub-tree. Such a reference is analogous to a free variable, and can play a similar role. Indeed, one of the reasons for using explicit references via labels is to allow for that possibility.

No particular constraints are placed on nodes which appear in separate programs, or in fact, on the appearance of the same node within multiple programs. That is, if a system contains two different programs, \todo{}

For the sake of modularity, types and attribute names are associated with namespaces, so that simple names can be used without fear of unintentional collisions. For example, a conditional expression in the kernel language (discussed later) is represented as a node of type \keyword{kernel/if} containing attributes \keyword{kernel/if/test}, etc.

This construction for nodes has some commonalities with the data constructors of a functional language such as Haskell: Nodes are used to build potentially recursive data structures in the same way you build a tree (or indeed an AST) from values. However nodes in this system are not typed, in the sense that a well-formed program can consist of any aggregation of nodes. This flexibility supports both interactivity and extension, but of course it's necessary to have a way to constrain programs to contain meaningful arrangements of nodes.


\subsection{Specifications}
A \emph{specification} is a set of constraints on the structure of nodes in a program, which can be expressed as predicates on the nodes. A program is \emph{valid} with respect to a certain specification if the arrangement of nodes, values, and references satisfies the specification's constraints. A specification can be thought of as a boolean-valued function over programs producing the result \emph{valid} or \emph{invalid}, in the same way that a conventional parser is a function over strings which returns either \emph{parses} or \emph {doesn't parse}.

For example, a certain specification might include the constraint ``for all nodes $n$, if the type of $n$ is \keyword{if}, then $n$ has an attribute \keyword{test}, whose type is (an instance of) \keyword{expr}.''

In practice a program may contain more than one violation of a specification, and the user will be interested in the nature of each violation in order to be able to fix them (by correcting either the program or the specification). Therefore a specification will typically be implemented in the form of a \emph{checker}, a function over programs which produces a set of \emph{errors} each consisting of a description of the problem and the location where it occurs.

Depending on the nature of the properties being checked, a specification may be defined only in terms of \emph{local} properties of individual nodes and their direct children, or may refer to \emph{non-local} relationships between nodes more distantly connected. In general, local properties are easier to define, easier to check, and easier to understand, so for the most part they are to be preferred. However, certain important specifications are non-local by nature, e.g. type safety. In section 3.2?\todo{}, we describe a particularly direct and convenient way of specifying the basic structural properties which are sufficient to define a useful programming language.

By providing a modular way of describing and checking properties of programs, specifications give much-needed structure to the open model of ASTs described in the preceding sections. But they do so in a way that does not ultimately restrict the user's ability to modify and extend her program. There is an analogy with the multi-level nature of an IDE: the main interface is a text editor, which can be used to enter arbitrary character sequences, but it is augmented with an ``online'' compiler, which parses the character stream into an AST and analyzes the program's types, etc. The information that is gleaned is then fed back to the text editor in the form of syntax hiliting, error indicators, and other helpful indications of the compiler's understanding. However, because in our system the program is not internally represented in an easily readable form, the presentation of it requires a more comprehensive approach.


\subsection{Reduction}
The next step in making a useful system is a way to produce (multiple) \emph{target} programs from a given \emph{source} program. The central idea is to have a single source program, consisting of nodes in some "user" programming language, which includes a node type for every important programming construct. In an extensible system, the user is able to add new types of nodes to a running system, but the underlying system must be supplied with some fixed set of node types that it understands. The way to bridge this gap is via \emph{reduction}.

As presented here, reduction is a restricted form of \emph{graph reduction}. It is inspired by the macro expansion of the LISP family of languages (\todo{cite e.g. Scheme}), and in fact the term ``expansion'' might be more appropriate because a typical reduction replaces a more abstract node with a potentially larger number of lower-level nodes.

A source progam is reduced to a target program by applying a \emph{reduction function} to the root node of the source program. If any reduction is possible, the reduction function returns a new, replacement root node, which typically repackages the children of the original root node under some new kind of parent. As long as some reduction is performed, the reduction function is applied repeatedly to the previous result. Eventually, the root node is fully-reduced (the function fails to return a new reduced node). At that point, each child node is reduced in the same way, and a new root node is constructed with the reduced children.

\todo{pseudocode?}

Note that during reduction a series of intermediate programs are produced which are partially reduced, and in general do not conform to the source or target specification. It might be interesting to investigate ways of defining reductions such that a valid program always reduces to a valid program. Perhaps if reduction functions were defined in the right way, they could be checked statically against the two specifications. In the prototyped system, reductions are implemented in such a way that they tolerate and report invalid sub-programs.

\todo{figure: schematic of a simple tree being reduced in steps}

\subsubsection{Passing information down}
A local reduction works by examining one node at a time, producing a reduced node which combines the children of the original node in a new way, possibly with some additional nodes inserted as well. This is sufficient for most needs, but in some cases it's necessary to propagate some additional information through the reduction process. A simple extension that meets many needs is to augment the reduction function described above to accept an additional \emph{environment} parameter, an arbitrary value, and to return both a reduced node and a new environment value to be propagated. When recursively visiting child nodes, the new value is used in place of the old one. This allows the reduction function to compute values based on the shape of the tree and use them to control some aspects of the reduction. For example, a reduction could keep track of the depth of the tree (distance from the root node).

\todo{Clearer description? Connection with inherited attributes?}


\subsubsection{Tracking source nodes}
When it's desirable to keep track of what source node gave rise to a given target node, the reduction can record the labels of each pair of source and target node, forming a kind of mapping between the parallel trees. For this to work, the reduction function needs to operate strictly on the single node it's given, and not to reach into any child node. This in turn places some constraints on the way the source program is constructed: each node (along with any environment) must bear sufficient information to identify the correct reduction.

\todo{figure: "links" back to source nodes, or would it make more sense later?}



\subsection{Kernel Language}
%The system depends on reduction functions and other program transformations which need to be written in some language, and no suitable language exists. We took this as a challenge and 

%Although in principle one could leave all the implementation outside the system itself and just say ``a certain transformation occurs,'' it is desirable from one point of view to use the system itself as a test case and see  Furthermore, it's desirable to have 

\todo{Having a hard time articulating the need/motivation for basing so much of the system on a kernel language, but I do feel I need to make the case. Is there a real alternative?}

Possible arguments:

- eat own dog food

- it makes a good test case for everything else

- it's a meta-programming problem

- have to ``bottom out'' somewhere - whatever that means

Requirements for the kernel language:
\begin{enumerate}
\item Be in some sense minimal but sufficient that everything else can be done via extensions of it.
\item Fit well with the ``functional'' approach to nodes and trees.
\item Be able to operate on nodes.
\end{enumerate}

